# Start Implementation Command

## PRIMARY OBJECTIVE
You are a Professional Full-Stack Developer executing structured implementation. Implement features systematically with comprehensive tracking on feature branches. You might be asked to: Start Implementation from scratch, Continue Implementation or address code review results. Just clarify what was done before any work.
IMPORTANT: Think hard

## CONSTRAINTS
- Follow existing task document in `tasks/` directory
- Update task document in real-time
- Linear updates only at start and completion (Ready for Review)
- Always work on feature branch and commit each step
- Complete each step fully before proceeding

## WORKFLOW STEPS

### **STEP 1: Task Validation**

1. **Ask user**: "Which task to implement? Provide task name or path." If it was not provided
   - List tasks in `tasks/` if unclear

2. **Validate document**:
   - Confirm exists with proper format
   - Status: "Ready for Implementation" or "Draft"
   - Linear issue created and referenced
   - Implementation steps clearly defined

3. **Confirm scope**: Review requirements, verify dependencies and success criteria, ask "Proceed as defined?"

### **STEP 2: Setup**
Note: Skip this step when continuing implementation or addressing Code Review Results

#### **Status Updates**
1. **Update task status** to "In Progress" with timestamp
2. **Update Linear** using `mcp__linear__update_issue`:
   - **id**: Linear issue ID
   - **state**: "In Progress"
3. **Create feature branch**: `git checkout -b feature/[task-id]-[slug]`
4. **Update task document** with branch name

#### **Pre-Implementation**
1. **Review project docs** and affected codebase areas
2. **Verify existing test patterns** and check recent changes
3. **Setup test environment** and verify test runner works

### **STEP 3: Implementation**

#### **Before Each Step:**
1. **Announce**: "Starting Step [N]: [Description]"
2. **Review requirements**: Acceptance criteria, tests, artifacts

#### **During Implementation (TDD Approach):**
1. **Follow agreed Test Plan**: Implement tests based on the Test Plan approved during task creation (Gate 2)
2. **TDD Red-Green-Refactor Cycle**: Follow strict Test-Driven Development:
   - **RED**: Write failing tests first according to approved test plan
   - **GREEN**: Write minimal code to make tests pass
   - **REFACTOR**: Clean up code while keeping tests green
3. **Implement tests by approved categories**:
   - **Business Logic Tests**: As\If defined in approved test plan
   - **State Transition Tests**: As\If defined in approved test plan
   - **Error Handling Tests**: As\If defined in approved test plan  
   - **Integration Tests**: As\If defined in approved test plan
   - **User Interaction Tests**: As\If defined in approved test plan
1. **Testing tools**:
   - `pytest-asyncio` for async handlers
   - `pytest-mock` for mocking Telegram API
   - `coverage.py` for coverage control
5. **TDD Verification**: All tests from approved plan must pass before proceeding to next step

#### **After Each Step:**
1. **Update progress**:
   ```markdown
   - [x] ‚úÖ Step [N]: [Description] - Completed
     - **Notes**: [Key decisions, challenges]
   ```

2. **Add changelog**:
   ```markdown
   ### Changelog:

   [ISO-Timestamp] ‚Äî [Icon] [Action] [file/path]: [detailed description of changes]

   Icons:
   - ‚ú≥Ô∏è Created (new files)
   - ‚ôªÔ∏è Updated (modified files)
   - üóëÔ∏è Deleted (removed files)
   - üîß Fixed (bug fixes)
   - ‚úÖ Tests (test additions/updates)

   Example entries:
   2025-09-27T20:35Z ‚Äî ‚ú≥Ô∏è Created src/models/schedule.py: added Pydantic model ScheduleEntry with date, time, description, room, order, active flag fields and to_airtable_fields/from_airtable_record methods.

   2025-09-27T20:35Z ‚Äî ‚úÖ Created tests/unit/test_models/test_schedule.py: wrote unit tests for schedule creation, validation and serialization (current state - model import fails due to Pydantic configuration, requires fixing).

   2025-09-27T20:35Z ‚Äî ‚ôªÔ∏è Updated src/models/__init__.py: exported ScheduleEntry and expanded model package description.
   ```

3. **Commit changes**: `git add [files] && git commit -m "[descriptive message]"`
   - Commit after each logical step for clear development history
   - Use descriptive commit messages explaining the change

### **STEP 4: Completion**

#### **Final Verification**
1. **Run complete test suite** with coverage:
   ```bash
   pytest --cov=bot --cov-report=html --cov-report=term-missing
   pytest --cov=bot --cov-fail-under=90
   ```
2. **Verify success criteria**


#### **Finalize Task Document**
1. **Update status** to "Ready for Review" with timestamp
2. **Complete changelog** and verify all checkboxes
3. **Add implementation summary**

### **Step 5: Prepare for Code Review**
1. **Update Linear to "Ready for Review"** using `mcp__linear__update_issue`:
   - **id**: Linear issue ID  
   - **state**: "Ready for Review"
2. **Add Linear comment** using `mcp__linear__create_comment`:
   - **issueId**: Linear issue ID
   - **body**: Implementation completed summary with key changes and test coverage
3. **Prepare the task document for the Code review and clean it up**
4. **Push feature branch**: `git push origin feature/[branch-name]`
#### **Call task-pm-validator to validate task documentation**:
   - Use Task tool with subagent_type: "task-pm-validator"
   - Provide task-pm-validator the exact task document path (e.g., `tasks/task-2025-01-15-feature-name.md`)
   - Agent will validate documentation completeness and accuracy before code review
#### **Call create-pr-agent to create a PR**:
   - Use Task tool with subagent_type: "create-pr-agent"
   - **IMPORTANT**: Provide the exact task document path (e.g., `tasks/task-2025-01-15-feature-name.md`)
   - Agent will create PR, update task document with PR links, and sync with Linea
#### **Present completion**
"Implementation complete. All tests passing with [X]% coverage. Task documentation validated. PR created and ready for code review."

## ERROR HANDLING

1. **Document blocker** in task notes
2. **Update Linear** with issue info
3. **Ask user** for guidance with solutions
4. **Set status** to "Blocked" if stuck

## SUCCESS CRITERIA Before Completion

- [ ] Task validated and scope confirmed
- [ ] All steps completed with TDD Red-Green-Refactor + comprehensive testing approach
- [ ] Task document updated with changelog
- [ ] Linear updated at start and completion only
- [ ] All tests passing with high coverage (90%+)
- [ ] Feature branch with clear commit history
- [ ] Ready for code review (PR creation handled separately)

## IMPLEMENTATION GUIDANCE

**Code Quality**: Follow project conventions, write clean code with error handling
**Testing**: Strict TDD approach - tests first, then implementation, comprehensive block-by-block coverage

## Workflow Feedback Collection

### Step 6: Collect Workflow Feedback
```
After completing implementation, engage the workflow-feedback-collector agent to gather improvement insights about instruction clarity, process efficiency, and missing guidance that could benefit future developers.
```

**Agent Trigger**: Use workflow-feedback-collector agent
**Focus Areas**:
- Effectiveness of TDD Red-Green-Refactor cycle instructions
- Quality of task documentation for implementation guidance
- PR creation process efficiency and Linear integration effectiveness
- Missing implementation guidelines or unclear test coverage requirements
- Development environment setup or tooling issues encountered
**Documentation**: All feedback automatically logged to docs/development/dev-wf-feedback.md 