#!/usr/bin/env python3
"""
Project Index Updater –¥–ª—è telegram-bot-v3

–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç project_index.json –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è—Ö –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –ø—Ä–æ–µ–∫—Ç–∞.
–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç Python —Ñ–∞–π–ª—ã –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è AI-–∞–≥–µ–Ω—Ç–æ–≤.
"""

import os
import json
import ast
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional
import fnmatch
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('indexer')

class ProjectIndexer:
    """–ò–Ω–¥–µ–∫—Å–µ—Ä –ø—Ä–æ–µ–∫—Ç–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è."""
    
    def __init__(self, project_path: str):
        self.project_path = Path(project_path)
        self.gitignore_patterns = self._load_gitignore()
        self.src_path = self.project_path / 'src'
        
    def _load_gitignore(self) -> List[str]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏–∑ .gitignore –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤."""
        gitignore_path = self.project_path / '.gitignore'
        default_patterns = [
            '__pycache__', '*.pyc', '*.pyo', '*.pyd', 
            '.git', 'venv', '.env', '.venv',
            '*.egg-info', 'dist', 'build',
            '.DS_Store', '.pytest_cache'
        ]
        
        if gitignore_path.exists():
            try:
                with open(gitignore_path, 'r', encoding='utf-8') as f:
                    patterns = [line.strip() for line in f 
                              if line.strip() and not line.startswith('#')]
                    default_patterns.extend(patterns)
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è .gitignore: {e}")
        
        return default_patterns
    
    def _should_ignore(self, file_path: Path) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –¥–æ–ª–∂–µ–Ω –ª–∏ —Ñ–∞–π–ª –±—ã—Ç—å –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω."""
        try:
            relative_path = file_path.relative_to(self.project_path)
            
            for pattern in self.gitignore_patterns:
                if fnmatch.fnmatch(str(relative_path), pattern):
                    return True
                if fnmatch.fnmatch(relative_path.name, pattern):
                    return True
                    
        except ValueError:
            # –§–∞–π–ª –Ω–µ –≤ –ø—Ä–æ–µ–∫—Ç–µ
            return True
            
        return False
    
    def _analyze_python_file(self, file_path: Path) -> Optional[Dict[str, Any]]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç Python —Ñ–∞–π–ª –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é."""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            tree = ast.parse(content)
            
            analysis = {
                'role': self._determine_file_role(file_path),
                'purpose': self._extract_module_docstring(tree),
                'key_exports': [],
                'dependencies': [],
                'features': []
            }
            
            # –ê–Ω–∞–ª–∏–∑ –∏–º–ø–æ—Ä—Ç–æ–≤
            imports = []
            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        imports.append(alias.name)
                        if alias.name.startswith('src.'):
                            analysis['dependencies'].append(alias.name)
                elif isinstance(node, ast.ImportFrom):
                    if node.module:
                        imports.append(node.module)
                        if node.module.startswith('src.'):
                            analysis['dependencies'].append(node.module)
            
            # –ê–Ω–∞–ª–∏–∑ —ç–∫—Å–ø–æ—Ä—Ç–æ–≤
            exports = []
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    if not node.name.startswith('_'):  # –ü—É–±–ª–∏—á–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
                        exports.append(node.name)
                elif isinstance(node, ast.ClassDef):
                    exports.append(node.name)
                elif isinstance(node, ast.Assign):
                    for target in node.targets:
                        if isinstance(target, ast.Name) and target.id.isupper():
                            exports.append(target.id)
            
            analysis['key_exports'] = exports[:5]  # –¢–æ–ø 5 —ç–∫—Å–ø–æ—Ä—Ç–æ–≤
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–µ–π —Ñ–∞–π–ª–∞
            analysis['features'] = self._detect_features(tree, content)
            
            return analysis
            
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ {file_path}: {e}")
            return None
    
    def _determine_file_role(self, file_path: Path) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ä–æ–ª—å —Ñ–∞–π–ª–∞ –≤ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ."""
        relative_path = str(file_path.relative_to(self.project_path))
        
        if 'main.py' in file_path.name:
            return 'application_entry_point'
        elif 'test_' in file_path.name or '/tests/' in relative_path:
            return 'test'
        elif '/models/' in relative_path:
            return 'domain_model'
        elif '/services/' in relative_path:
            return 'business_service'
        elif '/data/' in relative_path or '/repositories/' in relative_path:
            return 'data_access_layer'
        elif '/bot/' in relative_path or '/handlers/' in relative_path:
            return 'presentation_layer'
        elif '/config/' in relative_path:
            return 'configuration'
        elif '/utils/' in relative_path:
            return 'utility'
        else:
            return 'module'
    
    def _extract_module_docstring(self, tree: ast.AST) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç docstring –º–æ–¥—É–ª—è."""
        if (isinstance(tree, ast.Module) and tree.body and 
            isinstance(tree.body[0], ast.Expr) and 
            isinstance(tree.body[0].value, ast.Constant)):
            docstring = tree.body[0].value.value
            if isinstance(docstring, str):
                # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É docstring
                return docstring.split('\n')[0].strip()
        return ""
    
    def _detect_features(self, tree: ast.AST, content: str) -> List[str]:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –∏ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤ –∫–æ–¥–µ."""
        features = []
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ async/await
        for node in ast.walk(tree):
            if isinstance(node, ast.AsyncFunctionDef):
                features.append('async_patterns')
                break
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ Pydantic
        if 'pydantic' in content or 'BaseModel' in content:
            features.append('pydantic_validation')
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ enum
        if 'from enum import' in content or 'Enum' in content:
            features.append('enum_types')
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ Airtable –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é
        if 'airtable' in content.lower():
            features.append('airtable_integration')
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
        if 'logging' in content:
            features.append('logging')
            
        return features
    
    def _generate_project_tree(self) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –¥—Ä–µ–≤–æ–≤–∏–¥–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞."""
        def build_tree_part(path: Path, level: int = 0, is_last: bool = True) -> List[str]:
            items = []
            
            if level == 0:
                items.append(f"{self.project_path.name}/")
                level = 1
            
            try:
                # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ª—å–∫–æ –≤–∞–∂–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –∏ —Ñ–∞–π–ª—ã
                entries = []
                if path.is_dir():
                    for item in sorted(path.iterdir()):
                        if not self._should_ignore(item):
                            entries.append(item)
                
                # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –∏ —Ñ–∞–π–ª—ã
                dirs = [p for p in entries if p.is_dir()]
                files = [p for p in entries if p.is_file() and self._is_important_file(p)]
                
                all_items = dirs + files
                
                for i, item in enumerate(all_items):
                    is_last_item = (i == len(all_items) - 1)
                    prefix = "‚îî‚îÄ‚îÄ " if is_last_item else "‚îú‚îÄ‚îÄ "
                    indent = "    " * (level - 1)
                    
                    if item.is_dir():
                        items.append(f"{indent}{prefix}{item.name}/")
                        if level < 3:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –≥–ª—É–±–∏–Ω—É
                            sub_items = build_tree_part(item, level + 1, is_last_item)
                            items.extend(sub_items)
                    else:
                        description = self._get_file_description(item)
                        display_name = f"{item.name} ({description})" if description else item.name
                        items.append(f"{indent}{prefix}{display_name}")
                        
            except PermissionError:
                pass
                
            return items
        
        tree_lines = build_tree_part(self.project_path)
        return '\n'.join(tree_lines)
    
    def _is_important_file(self, file_path: Path) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª –≤–∞–∂–Ω—ã–º –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –¥–µ—Ä–µ–≤–µ."""
        important_files = {
            'main.py', 'settings.py', 'conftest.py', 
            'README.md', 'CLAUDE.md', 'requirements.txt',
            'pyproject.toml', 'start_bot.sh', 'project_index.json'
        }
        
        important_patterns = ['*.py', '*.md', '*.txt', '*.toml', '*.sh', '*.json']
        
        if file_path.name in important_files:
            return True
            
        for pattern in important_patterns:
            if fnmatch.fnmatch(file_path.name, pattern):
                return True
                
        return False
    
    def _get_file_description(self, file_path: Path) -> str:
        """–ü–æ–ª—É—á–∞–µ—Ç –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ñ–∞–π–ª–∞."""
        descriptions = {
            'main.py': 'application entry point',
            'settings.py': 'centralized app configuration',
            'conftest.py': 'pytest configuration',
            'participant.py': 'participant data model with enums',
            'search_service.py': 'fuzzy search with Russian/English support',
            'search_conversation.py': 'main search conversation flow',
            'airtable_client.py': 'low-level Airtable API client',
            'airtable_participant_repo.py': 'participant repository',
            'field_mappings.py': 'Airtable field ID mappings',
            'CLAUDE.md': 'project guidance for Claude Code',
            'start_bot.sh': 'bot startup script'
        }
        
        return descriptions.get(file_path.name, '')
    
    def update_index(self) -> Dict[str, Any]:
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –∏–Ω–¥–µ–∫—Å –ø—Ä–æ–µ–∫—Ç–∞."""
        logger.info("üîç –ù–∞—á–∏–Ω–∞—é –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ –ø—Ä–æ–µ–∫—Ç–∞...")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∏–Ω–¥–µ–∫—Å
        index_file = self.project_path / 'project_index.json'
        existing_index = {}
        
        if index_file.exists():
            try:
                with open(index_file, 'r', encoding='utf-8') as f:
                    existing_index = json.load(f)
                logger.info("üìÑ –ó–∞–≥—Ä—É–∂–µ–Ω —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∏–Ω–¥–µ–∫—Å")
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –∏–Ω–¥–µ–∫—Å–∞: {e}")
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è —É–¥–∞–ª–µ–Ω–Ω—ã—Ö
        current_files = set()
        if self.src_path.exists():
            for py_file in self.src_path.rglob('*.py'):
                if not self._should_ignore(py_file) and py_file.name != '__init__.py':
                    relative_path = str(py_file.relative_to(self.project_path))
                    current_files.add(relative_path)
        
        # –ù–∞–π—Ç–∏ —É–¥–∞–ª–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        old_files = set()
        if 'key_modules' in existing_index:
            old_files = set(existing_index['key_modules'].keys())
        
        deleted_files = old_files - current_files
        new_files = current_files - old_files
        
        if deleted_files:
            logger.info(f"üóëÔ∏è  –£–¥–∞–ª–µ–Ω—ã —Ñ–∞–π–ª—ã: {', '.join(deleted_files)}")
        if new_files:
            logger.info(f"‚ûï –î–æ–±–∞–≤–ª–µ–Ω—ã —Ñ–∞–π–ª—ã: {', '.join(new_files)}")
        
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –≤–µ—Ä—Å–∏—é –∏–Ω–¥–µ–∫—Å–∞
        updated_index = {
            "project_overview": {
                "name": "telegram-bot-v3",
                "description": "Telegram bot for participant management with Airtable integration and Russian/English fuzzy search",
                "architecture": "3-layer architecture (bot/services/data) with repository pattern",
                "main_language": "python",
                "last_updated": datetime.now().isoformat()
            }
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø—Ä–æ–µ–∫—Ç–∞
        updated_index["project_structure"] = {
            "tree": self._generate_project_tree(),
            "directory_details": existing_index.get("project_structure", {}).get("directory_details", {}),
            "key_files": existing_index.get("project_structure", {}).get("key_files", {})
        }
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–ª—é—á–µ–≤—ã–µ –º–æ–¥—É–ª–∏
        key_modules = {}
        python_files_analyzed = 0
        
        if self.src_path.exists():
            for py_file in self.src_path.rglob('*.py'):
                if not self._should_ignore(py_file) and py_file.name != '__init__.py':
                    relative_path = str(py_file.relative_to(self.project_path))
                    analysis = self._analyze_python_file(py_file)
                    
                    if analysis:
                        key_modules[relative_path] = analysis
                        python_files_analyzed += 1
        
        updated_index["key_modules"] = key_modules
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Ä–∞–∑–¥–µ–ª—ã –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –∏–Ω–¥–µ–∫—Å–∞
        sections_to_preserve = [
            "architecture_patterns", "key_features", 
            "current_development_context", "testing_approach",
            "environment_requirements"
        ]
        
        for section in sections_to_preserve:
            if section in existing_index:
                updated_index[section] = existing_index[section]
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        updated_index["project_statistics"] = {
            "total_python_files": python_files_analyzed,
            "main_directories": ["src/bot", "src/services", "src/data", "src/models", "src/config", "tests"],
            "key_dependencies": ["telegram", "airtable", "pydantic", "rapidfuzz", "pytest"]
        }
        
        logger.info(f"‚úÖ –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {python_files_analyzed} Python —Ñ–∞–π–ª–æ–≤")
        return updated_index

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞."""
    if len(sys.argv) < 2:
        project_path = Path.cwd()
    else:
        project_path = Path(sys.argv[1])
    
    if not project_path.exists():
        logger.error(f"‚ùå –ü—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {project_path}")
        sys.exit(1)
    
    try:
        indexer = ProjectIndexer(str(project_path))
        updated_index = indexer.update_index()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –∏–Ω–¥–µ–∫—Å
        index_file = project_path / 'project_index.json'
        with open(index_file, 'w', encoding='utf-8') as f:
            json.dump(updated_index, f, indent=2, ensure_ascii=False)
        
        logger.info(f"‚úÖ –ò–Ω–¥–µ–∫—Å —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω: {index_file}")
        print(f"üéâ –ò–Ω–¥–µ–∫—Å –ø—Ä–æ–µ–∫—Ç–∞ –æ–±–Ω–æ–≤–ª–µ–Ω: {datetime.now().strftime('%H:%M:%S')}")
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞: {e}")
        sys.exit(1)

if __name__ == '__main__':
    main()